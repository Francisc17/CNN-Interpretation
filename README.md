# CNN-Interpretation
Exploration of different techniques to interpret the result and the logic behind a prediction made by a convolutional neural network (CNN)

Convolutional Neural Network (CNN) interpretation techniques are methods used to gain insights into the decision-making process of CNNs, which are popular deep learning models for tasks like image classification. These techniques aim to make CNNs more transparent by highlighting important regions or features within an input image that contribute to the model's predictions. CNN interpretation techniques are crucial for understanding and debugging models, ensuring they make accurate and meaningful decisions, and for building trust in AI systems by providing human-interpretable insights into their functioning.

All the techniques used:
- GradCAM
- Lime
- Rise
- Saliency Maps
- Anchor Explanations
- Activation Maximization
- Occlusion sensitivity
- Guided Backpropagation
- Deep Dream
