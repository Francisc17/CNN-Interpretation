{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RISE - Randomized Image Sampling for Explanations","metadata":{}},{"cell_type":"markdown","source":"## Theoretical Explanation","metadata":{}},{"cell_type":"markdown","source":"References:\n* https://arxiv.org/pdf/1806.07421.pdf\n* https://www.researchgate.net/publication/325893765_RISE_Randomized_Input_Sampling_for_Explanation_of_Black-box_Models\n* https://github.com/eclique/RISE","metadata":{}},{"cell_type":"markdown","source":"RISE queries black-box model on multiple randomly masked versions of input. After all the queries are done we average all the masks with respect to their scores to produce the final saliency map. The idea behind this is that whenever a mask preserves important parts of the image it gets higher score, and consequently has a higher weight in the sum.\n\n<img src=\"https://camo.githubusercontent.com/a41672d5047e7c371e0854bd23b5cab5487a7a158aa41bd61470d9220dab62c6/68747470733a2f2f65636c697175652e6769746875622e696f2f7265702d696d67732f524953452f726973652d6f766572766965772e706e67\" width=\"800\">","metadata":{}},{"cell_type":"markdown","source":"## Tensorflow General configs and imports","metadata":{}},{"cell_type":"code","source":"# Python ≥3.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn ≥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\ntry:\n    # %tensorflow_version only exists in Colab.\n    %tensorflow_version 2.x\nexcept Exception:\n    pass\n\n# TensorFlow ≥2.0 is required\nimport tensorflow as tf\nassert tf.__version__ >= \"2.0\"\n\n# Common imports\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport os\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n\n# Ignore useless warnings (see SciPy issue #5998)\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:03:37.320134Z","iopub.execute_input":"2022-09-22T17:03:37.320615Z","iopub.status.idle":"2022-09-22T17:03:43.165523Z","shell.execute_reply.started":"2022-09-22T17:03:37.320566Z","shell.execute_reply":"2022-09-22T17:03:43.164369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Activation, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras import optimizers, regularizers\nfrom tensorflow.keras.applications.xception import Xception\nfrom keras.applications.xception import preprocess_input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow import keras\nfrom IPython.display import Image, display\nimport matplotlib.cm as cm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom matplotlib.colors import BoundaryNorm\nfrom matplotlib.colorbar import ColorbarBase\nimport pathlib\nfrom skimage.transform import resize\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:03:43.167508Z","iopub.execute_input":"2022-09-22T17:03:43.168242Z","iopub.status.idle":"2022-09-22T17:03:44.494503Z","shell.execute_reply.started":"2022-09-22T17:03:43.168190Z","shell.execute_reply":"2022-09-22T17:03:44.493394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data pre-processing","metadata":{}},{"cell_type":"code","source":"# Obtain and prepare dataset\n\ndata_dir = pathlib.Path('../input/monkeypoxdataset/MonkeypoxSkinDataset')\n\n# Input size Final\nbatch_size = 32\nIMG_SIZE = (124,124)\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  shuffle=True,\n  image_size=IMG_SIZE,\n  batch_size=batch_size)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  shuffle=True,\n  image_size=IMG_SIZE,\n  batch_size=batch_size)\n\nclass_names = train_ds.class_names","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:03:44.496221Z","iopub.execute_input":"2022-09-22T17:03:44.496573Z","iopub.status.idle":"2022-09-22T17:04:36.968170Z","shell.execute_reply.started":"2022-09-22T17:03:44.496537Z","shell.execute_reply":"2022-09-22T17:04:36.967028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_ds.cache().prefetch(1)\nval_ds = val_ds.cache().prefetch(1)\n\nval_batches = val_ds.cardinality().numpy()\ntest_ds = val_ds.take(val_batches // 3) \nval_ds = val_ds.skip(val_batches // 3)\n\nnormalization_layer = keras.layers.experimental.preprocessing.Rescaling(1./255)\n\ntrain_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nval_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\ntest_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:36.971589Z","iopub.execute_input":"2022-09-22T17:04:36.971922Z","iopub.status.idle":"2022-09-22T17:04:37.061419Z","shell.execute_reply.started":"2022-09-22T17:04:36.971893Z","shell.execute_reply":"2022-09-22T17:04:37.060401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Learning on Xception model","metadata":{}},{"cell_type":"code","source":"# create the base pre-trained model\nbase_model = keras.applications.xception.Xception(weights='imagenet', include_top=False)\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# and a logistic layer -- let's say we have 6 classes\npredictions = Dense(6, activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:37.063023Z","iopub.execute_input":"2022-09-22T17:04:37.063585Z","iopub.status.idle":"2022-09-22T17:04:38.810846Z","shell.execute_reply.started":"2022-09-22T17:04:37.063547Z","shell.execute_reply":"2022-09-22T17:04:38.809698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:38.812413Z","iopub.execute_input":"2022-09-22T17:04:38.812821Z","iopub.status.idle":"2022-09-22T17:04:38.825519Z","shell.execute_reply.started":"2022-09-22T17:04:38.812782Z","shell.execute_reply":"2022-09-22T17:04:38.822292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:38.827441Z","iopub.execute_input":"2022-09-22T17:04:38.827961Z","iopub.status.idle":"2022-09-22T17:04:38.845050Z","shell.execute_reply.started":"2022-09-22T17:04:38.827902Z","shell.execute_reply":"2022-09-22T17:04:38.844009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model if already trained\n# Ignore warning \"Could not open..\" - it will work even with that message\n\nmodel.load_weights('../input/xceptionmodeltf/xceptionmodeltfv2')","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:38.846891Z","iopub.execute_input":"2022-09-22T17:04:38.847310Z","iopub.status.idle":"2022-09-22T17:04:40.687463Z","shell.execute_reply.started":"2022-09-22T17:04:38.847266Z","shell.execute_reply":"2022-09-22T17:04:40.686452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Even if you load an already trained model in cell above you need to compile it as well\n\noptimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['accuracy'],\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:40.692063Z","iopub.execute_input":"2022-09-22T17:04:40.692827Z","iopub.status.idle":"2022-09-22T17:04:40.709755Z","shell.execute_reply.started":"2022-09-22T17:04:40.692796Z","shell.execute_reply":"2022-09-22T17:04:40.708510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training (will take time if no GPU or TPU is being used - even with GPU/TPU it takes a while)\n# Dont run it if you already load the weights\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs = 10,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Results visualization\n# Loss and validation loss variation \n\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:51:47.651777Z","iopub.status.idle":"2022-09-21T10:51:47.652115Z","shell.execute_reply.started":"2022-09-21T10:51:47.651951Z","shell.execute_reply":"2022-09-21T10:51:47.651967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Save the previous trained model\n\nmodelSaving = model.save_weights('./xceptionmodel', save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-09-21T10:51:47.653580Z","iopub.status.idle":"2022-09-21T10:51:47.653940Z","shell.execute_reply.started":"2022-09-21T10:51:47.653775Z","shell.execute_reply":"2022-09-21T10:51:47.653794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test sample evaluation\n\nscore = model.evaluate(test_ds)\nprint(\"Test loss: \", score[0])\nprint(\"Test accuracy: \", score[1])","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:40.711407Z","iopub.execute_input":"2022-09-22T17:04:40.714482Z","iopub.status.idle":"2022-09-22T17:04:58.271428Z","shell.execute_reply.started":"2022-09-22T17:04:40.714451Z","shell.execute_reply":"2022-09-22T17:04:58.270322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RISE implementation","metadata":{}},{"cell_type":"code","source":"class Model():\n    def __init__(self):\n        self.model = model\n        self.input_size = (224, 224)\n        \n    def run_on_batch(self, x):\n        return self.model.predict(x)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.273396Z","iopub.execute_input":"2022-09-22T17:04:58.273842Z","iopub.status.idle":"2022-09-22T17:04:58.280363Z","shell.execute_reply.started":"2022-09-22T17:04:58.273799Z","shell.execute_reply":"2022-09-22T17:04:58.278904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_img(path):\n    img = image.load_img(path, target_size=model.input_size)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    return img, x","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.282239Z","iopub.execute_input":"2022-09-22T17:04:58.282685Z","iopub.status.idle":"2022-09-22T17:04:58.292753Z","shell.execute_reply.started":"2022-09-22T17:04:58.282626Z","shell.execute_reply":"2022-09-22T17:04:58.291233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_masks(N, s, p1):\n    cell_size = np.ceil(np.array(model.input_size) / s)\n    up_size = (s + 1) * cell_size\n\n    grid = np.random.rand(N, s, s) < p1\n    grid = grid.astype('float32')\n\n    masks = np.empty((N, *model.input_size))\n\n    for i in tqdm(range(N), desc='Generating masks'):\n        # Random shifts\n        x = np.random.randint(0, cell_size[0])\n        y = np.random.randint(0, cell_size[1])\n        # Linear upsampling and cropping\n        masks[i, :, :] = resize(grid[i], up_size, order=1, mode='reflect',\n                                anti_aliasing=False)[x:x + model.input_size[0], y:y + model.input_size[1]]\n    masks = masks.reshape(-1, *model.input_size, 1)\n    return masks","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.294631Z","iopub.execute_input":"2022-09-22T17:04:58.295289Z","iopub.status.idle":"2022-09-22T17:04:58.306395Z","shell.execute_reply.started":"2022-09-22T17:04:58.295245Z","shell.execute_reply":"2022-09-22T17:04:58.304718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100\n\ndef explain(model, inp, masks):\n    preds = []\n    # Make sure multiplication is being done for correct axes\n    masked = inp * masks\n    for i in tqdm(range(0, N, batch_size), desc='Explaining'):\n        preds.append(model.run_on_batch(masked[i:min(i+batch_size, N)]))\n    preds = np.concatenate(preds)\n    sal = preds.T.dot(masks.reshape(N, -1)).reshape(-1, *model.input_size)\n    sal = sal / N / p1\n    return sal","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.308703Z","iopub.execute_input":"2022-09-22T17:04:58.309127Z","iopub.status.idle":"2022-09-22T17:04:58.320365Z","shell.execute_reply.started":"2022-09-22T17:04:58.309091Z","shell.execute_reply":"2022-09-22T17:04:58.318893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def class_name(idx):\n    return decode_predictions(np.eye(1, 1000, idx))[0][0][1]","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.322481Z","iopub.execute_input":"2022-09-22T17:04:58.323044Z","iopub.status.idle":"2022-09-22T17:04:58.329917Z","shell.execute_reply.started":"2022-09-22T17:04:58.323004Z","shell.execute_reply":"2022-09-22T17:04:58.328702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.333626Z","iopub.execute_input":"2022-09-22T17:04:58.334081Z","iopub.status.idle":"2022-09-22T17:04:58.339527Z","shell.execute_reply.started":"2022-09-22T17:04:58.334052Z","shell.execute_reply":"2022-09-22T17:04:58.338423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, x = load_img('../input/monkeypoxdataset/MonkeypoxSkinDataset/chickenpox/aug_ch_0001_0005.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.340992Z","iopub.execute_input":"2022-09-22T17:04:58.341898Z","iopub.status.idle":"2022-09-22T17:04:58.362367Z","shell.execute_reply.started":"2022-09-22T17:04:58.341854Z","shell.execute_reply":"2022-09-22T17:04:58.361291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 2000\ns = 8\np1 = 0.5\nmasks = generate_masks(2000, 8, 0.5)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:04:58.363924Z","iopub.execute_input":"2022-09-22T17:04:58.364531Z","iopub.status.idle":"2022-09-22T17:05:03.667240Z","shell.execute_reply.started":"2022-09-22T17:04:58.364489Z","shell.execute_reply":"2022-09-22T17:05:03.665887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sal = explain(model, x, masks)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:05:03.669129Z","iopub.execute_input":"2022-09-22T17:05:03.669540Z","iopub.status.idle":"2022-09-22T17:05:17.838465Z","shell.execute_reply.started":"2022-09-22T17:05:03.669497Z","shell.execute_reply":"2022-09-22T17:05:17.834109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:05:17.840296Z","iopub.execute_input":"2022-09-22T17:05:17.841080Z","iopub.status.idle":"2022-09-22T17:05:17.864155Z","shell.execute_reply.started":"2022-09-22T17:05:17.841031Z","shell.execute_reply":"2022-09-22T17:05:17.862688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_idx = 0\n\nplt.title('Explanation for {}'.format(class_names[class_idx]))\nplt.axis('off')\nplt.imshow(img)\nplt.imshow(sal[class_idx], cmap='jet', alpha=0.5)\n# plt.colorbar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T17:05:17.866313Z","iopub.execute_input":"2022-09-22T17:05:17.873886Z","iopub.status.idle":"2022-09-22T17:05:18.211550Z","shell.execute_reply.started":"2022-09-22T17:05:17.873827Z","shell.execute_reply":"2022-09-22T17:05:18.210557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It seems less accurate than the GradCAM algorithm but we need better data to validate that**","metadata":{}}]}